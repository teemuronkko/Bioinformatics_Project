{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate and Bivariate Von Mises distributions implemented in Numpyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as np\n",
    "import jax.random as random\n",
    "from jax.scipy.special import gammaln, logsumexp\n",
    "from jax import jit, lax\n",
    "from numpyro.distributions import constraints \n",
    "from numpyro.distributions.distribution import Distribution \n",
    "from numpyro.util import copy_docs_from\n",
    "from functools import partial\n",
    "from numpyro.distributions.util import lazy_property, promote_shapes, validate_sample\n",
    "from functools import reduce\n",
    "\n",
    "\"\"\"The implementation of the univariate Von Mises distribution follows the implementation of the same\n",
    "distribution in Pytorch torch.distributions package. The original code for the Pytorch implementation can be \n",
    "found athttps://pytorch.org/docs/stable/_modules/torch/distributions/von_mises.html#VonMises\"\"\"\n",
    "\n",
    "_I0_COEF_SMALL = np.array([1.0, 3.5156229, 3.0899424, 1.2067492, 0.2659732, 0.360768e-1, 0.45813e-2])\n",
    "_I0_COEF_LARGE = np.array([0.39894228, 0.1328592e-1, 0.225319e-2, -0.157565e-2, 0.916281e-2,\n",
    "                  -0.2057706e-1, 0.2635537e-1, -0.1647633e-1, 0.392377e-2])\n",
    "_I1_COEF_SMALL = np.array([0.5, 0.87890594, 0.51498869, 0.15084934, 0.2658733e-1, 0.301532e-2, 0.32411e-3])\n",
    "_I1_COEF_LARGE = np.array([0.39894228, -0.3988024e-1, -0.362018e-2, 0.163801e-2, -0.1031555e-1,\n",
    "                  0.2282967e-1, -0.2895312e-1, 0.1787654e-1, -0.420059e-2])\n",
    "\n",
    "@jit\n",
    "def _log_modified_bessel_fn(x, order):\n",
    "    \"\"\"\n",
    "    Returns ``log(I_order(x))`` for ``x > 0``,\n",
    "    where `order` is either 0 or 1.\n",
    "    \n",
    "    Based on https://pytorch.org/docs/stable/_modules/torch/distributions/von_mises.html#VonMises\n",
    "    \"\"\"\n",
    "    # compute small solution\n",
    "    y = (x / 3.75)\n",
    "    y = y * y\n",
    "    \n",
    "    COEF_SMALL = np.where(np.ones((7,))*order, _I1_COEF_SMALL, _I0_COEF_SMALL)\n",
    "    COEF_LARGE = np.where(np.ones((9,))*order, _I1_COEF_LARGE, _I0_COEF_LARGE)\n",
    "    \n",
    "    small = _eval_poly_small(y, COEF_SMALL)\n",
    "    small = np.where(np.ones(x.shape)*order, abs(x) * small, small)\n",
    "    small = np.log(small)\n",
    "\n",
    "    # compute large solution\n",
    "    y = 3.75 / x\n",
    "    large = x - 0.5 * np.log(x) + np.log(_eval_poly_large(y, COEF_LARGE))\n",
    "\n",
    "    result = np.where(x < 3.75, small, large)\n",
    "    return result\n",
    "\n",
    "@jit\n",
    "def _eval_poly_small(y, coef):\n",
    "    return coef[-7] + y*(coef[-6] + y*(coef[-5] + y*(coef[-4] + y*(coef[-3] + y*(coef[-2] + y*coef[-1])))))\n",
    "\n",
    "@jit\n",
    "def _eval_poly_large(y, coef):\n",
    "    return coef[-9] + y*(coef[-8] + y*(coef[-7] + y*( coef[-6] + \n",
    "                        y*(coef[-5] + y*(coef[-4] + y*(coef[-3] + y*(coef[-2] + y*coef[-1])))))))\n",
    "\n",
    "@jit\n",
    "def condition(args):\n",
    "    return ~np.all(args[2])\n",
    "\n",
    "@jit\n",
    "def loop(args):\n",
    "    x, proposal_r, done, key, concentration = args\n",
    "    key, subkey = jax.random.split(key)\n",
    "    u = jax.random.uniform(subkey, shape = (3,) + x.shape)\n",
    "    u1, u2, u3 = u.squeeze()\n",
    "    z = np.cos(np.pi * u1)\n",
    "    f = (1 + proposal_r * z) / (proposal_r + z)\n",
    "    c = concentration * (proposal_r - f)\n",
    "    accept = ((c * (2 - c) - u2) > 0) | (np.log(c / u2) + 1 - c >= 0)\n",
    "    x = np.where(accept, np.sign(u3 - 0.5) * np.arccos(f),  x)          \n",
    "    done = done | accept\n",
    "    return x, proposal_r, done, key, concentration\n",
    "\n",
    "@jit\n",
    "def _rejection_sample(loc, concentration, proposal_r, key, x):\n",
    "    \"\"\"\n",
    "    Acceptance-rejection sampling method – translated from the Pytorch Von Mises implementation. \n",
    "    \n",
    "    The sampling algorithm for the von Mises distribution is based on the following paper:\n",
    "    Best, D. J., and Nicholas I. Fisher.\n",
    "    \"Efficient simulation of the von Mises distribution.\" Applied Statistics (1979): 152-157.\n",
    "    \"\"\"\n",
    "    done = np.zeros(x.shape, dtype=bool)\n",
    "    x = lax.while_loop(condition, loop, (x, proposal_r, done, key, concentration))[0]\n",
    "    return (x + np.pi + loc) % (2 * np.pi) - np.pi\n",
    "    \n",
    "@copy_docs_from(Distribution)\n",
    "class VonMises(Distribution):\n",
    "    \"\"\"\n",
    "    A circular von Mises distribution.\n",
    "\n",
    "    This implementation uses polar coordinates. The ``loc`` and ``value`` args\n",
    "    can be any real number (to facilitate unconstrained optimization), but are\n",
    "    interpreted as angles modulo 2 pi.\n",
    "\n",
    "    :param int or ndarray: an angle in radians.\n",
    "    :param int ord ndarray: concentration parameter\n",
    "    \n",
    "    Based on https://pytorch.org/docs/stable/_modules/torch/distributions/von_mises.html#VonMises\n",
    "    \"\"\"\n",
    "    arg_constraints = {'loc': constraints.real, 'concentration': constraints.positive}\n",
    "    support = constraints.real\n",
    "    has_rsample = False\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(type(self).__name__) + \"(loc: \" + str(self.loc) + \", concentration: \" + str(self.concentration) + \")\"\n",
    "\n",
    "    def __init__(self, loc, concentration, validate_args=None):\n",
    "        self.loc, self.concentration = promote_shapes(loc, concentration)\n",
    "        batch_shape = lax.broadcast_shapes(np.shape(loc), np.shape(concentration))\n",
    "        event_shape = ()\n",
    "        tau = 1 + np.sqrt(1 + 4 * self.concentration ** 2)\n",
    "        rho = (tau - np.sqrt(2 * tau)) / (2 * self.concentration)\n",
    "        self._proposal_r = (1 + rho ** 2) / (2 * rho)\n",
    "        super(VonMises, self).__init__(batch_shape, event_shape, validate_args)\n",
    "\n",
    "    def log_prob(self, value):\n",
    "        log_prob = self.concentration * np.cos(value - self.loc)\n",
    "        log_prob = log_prob - np.log(2 * np.pi) - _log_modified_bessel_fn(self.concentration, 0)\n",
    "        return log_prob.T\n",
    "    \n",
    "    def sample(self, key, sample_shape = ()):\n",
    "        \"\"\"\n",
    "        The sampling algorithm for the von Mises distribution is based on the following paper:\n",
    "        Best, D. J., and Nicholas I. Fisher.\n",
    "        \"Efficient simulation of the von Mises distribution.\" Applied Statistics (1979): 152-157.\n",
    "        \n",
    "        Based on https://pytorch.org/docs/stable/_modules/torch/distributions/von_mises.html#VonMises\n",
    "        \"\"\"\n",
    "        if isinstance(sample_shape, int):\n",
    "            shape = tuple([sample_shape]) + self.batch_shape + self.event_shape\n",
    "        else:\n",
    "            shape = sample_shape + self.batch_shape + self.event_shape\n",
    "        x = np.empty(shape)            \n",
    "        return _rejection_sample(self.loc, self.concentration, self._proposal_r, key, x)\n",
    "\n",
    "    def expand(self, batch_shape):\n",
    "        \"\"\"\n",
    "        Function to initialize batch_shape number of parallel distributions\n",
    "        \"\"\"\n",
    "        validate_args = self.__dict__.get('_validate_args')\n",
    "        loc = np.ones(batch_shape)*self.loc\n",
    "        concentration = np.ones(batch_shape)*self.concentration\n",
    "        return VonMises(loc, concentration, validate_args=validate_args)\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        \"\"\"\n",
    "        The provided mean is the circular one.\n",
    "        \"\"\"\n",
    "        return self.loc\n",
    "\n",
    "    @lazy_property\n",
    "    def variance(self):\n",
    "        \"\"\"\n",
    "        The provided variance is the circular one.\n",
    "        \"\"\"\n",
    "        return 1 - np.exp(_log_modified_bessel_fn(self.concentration, 1) -\n",
    "                    _log_modified_bessel_fn(self.concentration, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Von Mises – sampling & logCinv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jit, static_argnums = (0,1,))\n",
    "def _acg_bound(sample, k1, k2, alpha, key):\n",
    "    lam = np.concatenate((np.zeros([len(k1), 1]), 0.5*(k1 - alpha**2/k2).reshape(len(k1), 1)), axis = 1)\n",
    "    lambda_min = np.min(lam, axis = 1).reshape([len(k1), 1])\n",
    "    lam = lam - lambda_min\n",
    "    b_values = np.concatenate((np.array(np.sqrt(lam[:,1]**2 + 1) - lam[:,1]\n",
    "                                        + 1).reshape([len(k1), 1]), np.ones([len(k1),1])*2), axis = 1)\n",
    "    b0 = np.min(b_values, axis = 1).reshape([len(k1), 1])\n",
    "\n",
    "    phi = 1 + 2*lam/b0\n",
    "    den = _log_modified_bessel_fn(k2, 0)\n",
    "    accept = np.zeros((sample.shape[0], k1.shape[0], 1), dtype = \"bool_\")\n",
    "    args = (key, phi, k1, k2, lam, lambda_min, sample, accept, den, b0, alpha)\n",
    "    res = lax.while_loop(loop_condition, loop_acg, args)[6]\n",
    "    \n",
    "    return np.arctan2(res[...,1], res[...,0])\n",
    "\n",
    "@jit\n",
    "def loop_acg(args):\n",
    "    key, phi, k1, k2, lam, lambda_min, sample, accept, den, b0, alpha = args\n",
    "    key, subkey = jax.random.split(key)\n",
    "    x = np.where(accept, 0,  jax.random.normal(subkey, sample.shape) * np.sqrt(1/phi))    \n",
    "    r = np.sqrt(np.sum(x**2, axis = -1))        \n",
    "    r = np.expand_dims(r, axis=-1)\n",
    "    x = x/r\n",
    "    u = (x**2 * lam).sum(-1)\n",
    "    v = jax.random.uniform(subkey, (sample.shape[0], k1.shape[0]))\n",
    "\n",
    "    logf = k1*(x[...,0] - 1) + lambda_min.T + _log_modified_bessel_fn(np.sqrt(k2**2 + alpha**2 * x[...,1]**2), 0) - den           \n",
    "    loggi = 0.5 * (2 - b0.T) + np.log(1 + 2*u/b0.T) + np.log(b0.T/2)\n",
    "    logfg = np.add(logf, loggi)\n",
    "    logfg = logfg.reshape([sample.shape[0], k1.shape[0]])\n",
    "    \n",
    "    accept = v < np.exp(logfg)\n",
    "    accept = accept[..., None]\n",
    "    sample = np.where(accept, x,  sample)\n",
    "\n",
    "    return (key, phi, k1, k2, lam, lambda_min, sample, accept, den, b0, alpha)\n",
    "\n",
    "@jit\n",
    "def loop_condition(args):\n",
    "    return np.count_nonzero(np.isnan(args[6])) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jit, static_argnums = (1,))\n",
    "def log_im(order, x): \n",
    "    \"\"\" x is a parameter, like k1 or k2\n",
    "        Based on '_log_modified_bessel_fn'\n",
    "        Tanabe, A., Fukumizu, K., Oba, S., Takenouchi, T., & Ishii, S. (2007). \n",
    "        Parameter estimation for von Mises–Fisher distributions. Computational Statistics, 22(1), 145-157. \n",
    "    \"\"\"\n",
    "    if not isinstance(x, int):\n",
    "        x = x.reshape([len(x), 1, 1])   \n",
    "    s = np.arange(0 , 251).reshape(251, 1)  \n",
    "    fs = 2 * s * np.log(x/2) - gammaln(s + 1) - gammaln(order + s + 1)\n",
    "    f_max = np.max(fs, axis = -2)\n",
    "    if hasattr(x, '__len__'):\n",
    "        x = x.reshape([len(x), 1])   \n",
    "   \n",
    "    return (order * np.log(x/2) + f_max + logsumexp(fs - f_max[:,None], -2)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jit, static_argnums = (0,))\n",
    "def log_C(k1, k2, lam):\n",
    "    \n",
    "    \"\"\"Harshinder Singh, Vladimir Hnizdo, and Eugene Demchuk\n",
    "    Probabilistic model for twodependent circular variables.\n",
    "    Biometrika, 89(3):719–723, 2002.\n",
    "\n",
    "    Closed form expression of the normalizing constant\n",
    "    Vectorized and in log-space\n",
    "    \n",
    "    k1, k2 & lam are the parameters from the bivariate von Mises\n",
    "    \n",
    "    Since the closed expression is an infinite sum, 'terms' is the number\n",
    "    of terms, over which the expression is summed over. Estimation by convergence. \n",
    "    \n",
    "    The code is translated to Numpyro from Christian Breinholt's Pytorch implementation.\"\"\"\n",
    "    \n",
    "    terms = 51\n",
    "    lam = np.abs(lam) + 1e-12\n",
    "    m = np.arange(0, terms)    \n",
    "    log_binom = gammaln(2*m+1) - 2*gammaln(m+1) \n",
    "    \n",
    "    logC = log_binom*np.ones((len(k1), terms)) + m*np.log((lam**2)/(4*k1*k2))[:,None] + log_im(m, k1) + log_im(m, k2)\n",
    "    \n",
    "    return - np.log(4*np.pi**2) - logsumexp(logC, axis = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Von Mises Distribution class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpyro.distributions.distribution import Distribution\n",
    "import time\n",
    "@copy_docs_from(Distribution)\n",
    "class BivariateVonMises(Distribution):\n",
    "    \"\"\"\n",
    "    Bivariate von Mises (Sine Model) distribution on the torus\n",
    "    \n",
    "    Modality:\n",
    "        If lam^2 / (k1*k2) > 1, the distribution is bimodal, otherwise unimodal.\n",
    "            - This distribution is only defined for some 'slightly' bimodal cases (alpha < -7)\n",
    "    \n",
    "    :param mu, nu: an angle in radians.\n",
    "        - mu & nu can be any real number but are interpreted as 2*pi\n",
    "    :param k1, k2: concentration parameters\n",
    "        - This distribution is only defined for k1, k2 > 0\n",
    "    :param lam: correlation parameter\n",
    "        - Can be any real number, but is not defined for very bimodal cases (see 'Modality')        \n",
    "    :param w: reparameterization parameter\n",
    "        - Has to be between -1 and 1\n",
    "    \"\"\"\n",
    "    arg_constraints = {'mu':  constraints.real, \n",
    "                       'nu':  constraints.real,\n",
    "                       'k1':  constraints.positive, \n",
    "                       'k2':  constraints.positive, \n",
    "                       'lam': constraints.real}\n",
    "    support = constraints.real\n",
    "    has_rsample = False\n",
    "    \n",
    "    def __repr__(self):\n",
    "        param = self.lam\n",
    "        printing = \", lam: \"\n",
    "        if self.lam is None:\n",
    "            param = self.w\n",
    "            printing = \", w: \"\n",
    "        return str(type(self).__name__) + \"(mu: \" + str(self.mu) + \", nu: \" + str(self.nu) + \", k1: \" + str(self.k1) + \", k2: \" + str(self.k2) + printing + str(param) + \")\"\n",
    "\n",
    "    def __init__(self, mu, nu, k1, k2, lam = None, w = None, validate_args = None):\n",
    "        \n",
    "        if lam is None == w is None:\n",
    "            raise ValueError(\"Either `lam` or `w` must be specified, but not both.\")\n",
    "        elif w is None:\n",
    "            self.mu, self.nu, self.k1, self.k2, self.lam = promote_shapes(mu, nu, k1, k2, lam)\n",
    "            alpha = 0.5*(self.k1 - (self.lam)**2/self.k2) \n",
    "            if not np.all(alpha > -7): \n",
    "                raise ValueError(\"Distribution is too bimodal or has too high concentration while being bimodal.\")\n",
    "        \n",
    "        elif lam is None:\n",
    "            self.mu, self.nu, self.k1, self.k2, self.w = promote_shapes(mu, nu, k1, k2, w)\n",
    "            self.lam = np.sqrt(self.k1*self.k2) * self.w\n",
    "            alpha = 0.5*(self.k1 - (self.lam)**2/self.k2) \n",
    "            if not np.all(alpha > -7): \n",
    "                raise ValueError(\"Distribution is too bimodal or has too high concentration while being bimodal.\")\n",
    "                \n",
    "        batch_shape = lax.broadcast_shapes(np.shape(self.mu), \n",
    "                                           np.shape(self.nu),\n",
    "                                           np.shape(self.k1),\n",
    "                                           np.shape(self.k2),\n",
    "                                           np.shape(self.lam))\n",
    "        event_shape = (2,)\n",
    "        \n",
    "        if isinstance(self.k1, int) or isinstance(self.k1, float):\n",
    "            self.logC = log_C(np.array([self.k1]), np.array([self.k2]), np.array([self.lam]))\n",
    "        else:\n",
    "            self.logC = log_C(self.k1, self.k2, self.lam)\n",
    "            \n",
    "        super(BivariateVonMises, self).__init__(batch_shape, event_shape, validate_args)\n",
    "    \n",
    "    def sample(self, key, sample_shape = (1)):\n",
    "        \"\"\" Harshinder Singh, Vladimir Hnizdo, and Eugene Demchuk\n",
    "            Probabilistic model for twodependent circular variables.\n",
    "            Biometrika, 89(3):719–723, 2002.\n",
    "            \n",
    "        marg: marginal distribution (using _acg_bound())\n",
    "        cond: conditional distribution using a modified univariate von Mises (as described in Singh et al. (2002))\n",
    "        \n",
    "        The sampling method follows Christian Breinholt's Pytorch implementation. \n",
    "        \"\"\"\n",
    "        if isinstance(sample_shape, int):\n",
    "            shape = tuple([sample_shape]) + self.batch_shape + self.event_shape\n",
    "        elif len(sample_shape) == 1:\n",
    "            shape = sample_shape + self.batch_shape + self.event_shape\n",
    "        else:\n",
    "            shape = tuple([reduce(lambda x, y: x*y, sample_shape)])  + self.batch_shape + self.event_shape\n",
    "            \n",
    "        x = np.empty(shape)*np.nan\n",
    "      \n",
    "        if isinstance(self.k1, int) or isinstance(self.k1, float):\n",
    "            marg = _acg_bound(x[:,None], np.array([self.k1])[:,None], np.array([self.k2])[:,None], np.array([self.lam])[:,None], key) #Sampling from marginal distribution\n",
    "            marg = (marg + self.mu + np.pi) % (2 * np.pi) - np.pi\n",
    "            marg = np.squeeze(marg)\n",
    "        elif len(self.k1) == 1:\n",
    "            marg = _acg_bound(x, self.k1[:,None], self.k2[:,None], self.lam[:,None], key) #Sampling from marginal distribution\n",
    "            marg = (marg + self.mu + np.pi) % (2 * np.pi) - np.pi\n",
    "            marg = np.squeeze(marg)\n",
    "        else:\n",
    "            marg = _acg_bound(x, self.k1, self.k2, self.lam, key)   #Sampling from marginal distribution\n",
    "            marg = (marg + self.mu + np.pi) % (2 * np.pi) - np.pi   #Applying mean angle\n",
    "          \n",
    "        alpha = np.sqrt(self.k2**2 + self.lam**2 * np.sin(marg - self.mu)**2) #Sampling from conditional distribution\n",
    "        beta  = np.arctan(self.lam / self.k2 * np.sin(marg - self.mu))\n",
    "        cond  = VonMises(self.nu + beta, alpha).sample(key)\n",
    "                \n",
    "        if isinstance(sample_shape, tuple):\n",
    "            if hasattr(self.k1, '__len__'):\n",
    "                if len(self.k1) > 1:\n",
    "                    marg = marg.T.reshape((len(self.k1),) + sample_shape)\n",
    "                    cond = cond.T.reshape((len(self.k1),) + sample_shape)\n",
    "                else: \n",
    "                    marg = marg.reshape(sample_shape)\n",
    "                    cond = cond.reshape(sample_shape)   \n",
    "            \n",
    "            else: \n",
    "                marg = marg.reshape(sample_shape)\n",
    "                cond = cond.reshape(sample_shape)\n",
    "\n",
    "        return np.stack([marg, cond], -1)\n",
    "    \n",
    "    def expand(self, batch_shape):\n",
    "        validate_args = self.__dict__.get('_validate_args')\n",
    "        mu = np.ones(batch_shape)*self.mu\n",
    "        nu = np.ones(batch_shape)*self.nu\n",
    "        k1 = np.ones(batch_shape)*self.k1\n",
    "        k2 = np.ones(batch_shape)*self.k2\n",
    "\n",
    "        if self.lam is not None:\n",
    "            lam = np.ones(batch_shape)*self.lam\n",
    "            w = None\n",
    "        else:\n",
    "            w = np.ones(batch_shape)*self.w\n",
    "            lam = None\n",
    "        \n",
    "        return BivariateVonMises(mu, nu, k1, k2, lam = lam, w = w, validate_args=validate_args)\n",
    "    \n",
    "    @validate_sample\n",
    "    def log_prob(self, angles):\n",
    "        \"\"\" Actual likelihood function, log joint distribution of phi and psi.\n",
    "        The code was translated from Christian Breinholt's Pytorch implementation\"\"\"\n",
    "            \n",
    "        phi = angles[...,0]\n",
    "        psi = angles[...,1]\n",
    "        \n",
    "        if hasattr(self.k1, '__len__'):\n",
    "            if len(self.k1) > 1: \n",
    "                N = angles[...,0].shape[-1]\n",
    "                k1 = self.k1.reshape((-1,) + (1,)*N)\n",
    "                k2 = self.k2.reshape((-1,) + (1,)*N)\n",
    "                mu = self.mu.reshape((-1,) + (1,)*N)\n",
    "                nu = self.nu.reshape((-1,) + (1,)*N)\n",
    "                lam = self.lam.reshape((-1,) + (1,)*N)\n",
    "                logC = self.logC.reshape((-1,) + (1,)*N)\n",
    "                \n",
    "                log_prob = k1*np.cos(phi - mu) + k2*np.cos(psi - nu)\n",
    "                log_prob += lam*np.sin(phi - mu)*np.sin(psi - nu)\n",
    "                log_prob += logC\n",
    "                return log_prob\n",
    "            else:\n",
    "                log_prob = self.k1*np.cos(phi - self.mu) + self.k2*np.cos(psi - self.nu)\n",
    "                log_prob += self.lam*np.sin(phi - self.mu)*np.sin(psi - self.nu)\n",
    "                log_prob += self.logC\n",
    "                return log_prob\n",
    "        else:\n",
    "            phi = phi.flatten()\n",
    "            psi = psi.flatten()\n",
    "            log_prob = self.k1*np.cos(phi - self.mu) + self.k2*np.cos(psi - self.nu)\n",
    "            log_prob += self.lam*np.sin(phi - self.mu)*np.sin(psi - self.nu)\n",
    "            log_prob += self.logC\n",
    "            return log_prob.reshape(angles[...,0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ramachandran_plot(data_angles, c):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.colors import LogNorm\n",
    "    degrees = np.rad2deg(data_angles) \n",
    "    phi = degrees[:,0] \n",
    "    psi = degrees[:,1] \n",
    "    plt.figure(figsize=(7, 6))\n",
    "    plt.hist2d(phi, psi, bins = 200, norm = LogNorm(), cmap = plt.cm.jet )\n",
    "    plt.suptitle(\"Ramachandran plot, {} samples from Bivariate von Mises\".format(n))\n",
    "    plt.title(\"mu = {}, nu = {}, k1 = {}, k2 = {}, lam = {}\".format(mu, nu, k1, k2, lam))\n",
    "    plt.xlabel('φ')\n",
    "    plt.ylabel('ψ')    \n",
    "    plt.xlim(-c, c)\n",
    "    plt.ylim(-c, c)\n",
    "    plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four parallel distributions \n",
    "– Sampling with sample shape (10, 2) and calculating log probability for samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[[-3.7041    , -3.493853  ],\n",
       "              [-3.6017377 , -2.2544556 ],\n",
       "              [-3.9106045 , -5.5328746 ],\n",
       "              [-2.5888896 , -3.006098  ],\n",
       "              [-2.5731888 , -3.025478  ],\n",
       "              [-2.344228  , -2.2679343 ],\n",
       "              [-3.013022  , -4.227346  ],\n",
       "              [-2.8640258 , -2.2765293 ],\n",
       "              [-4.976006  , -2.490044  ],\n",
       "              [-2.864221  , -2.9636009 ]],\n",
       "\n",
       "             [[ 1.5474396 ,  2.1278381 ],\n",
       "              [ 1.6512756 ,  2.2167816 ],\n",
       "              [ 1.7980347 , -0.12492371],\n",
       "              [-0.00796509,  1.9963226 ],\n",
       "              [ 2.123352  ,  0.77153015],\n",
       "              [ 1.9212341 ,  1.0536957 ],\n",
       "              [-0.42440796,  0.67684937],\n",
       "              [ 2.2994995 , -1.3942413 ],\n",
       "              [ 1.6056824 ,  0.13626862],\n",
       "              [ 1.1121063 ,  2.1580353 ]],\n",
       "\n",
       "             [[-3.1141508 , -2.6420875 ],\n",
       "              [-4.7155704 , -2.994446  ],\n",
       "              [-5.4422064 , -2.2678635 ],\n",
       "              [-2.9139745 , -3.64317   ],\n",
       "              [-2.6564288 , -3.4497733 ],\n",
       "              [-2.6629632 , -2.2515938 ],\n",
       "              [-2.256534  , -2.32264   ],\n",
       "              [-2.4350379 , -2.660349  ],\n",
       "              [-3.507281  , -2.2891812 ],\n",
       "              [-2.9578927 , -2.4852319 ]],\n",
       "\n",
       "             [[ 1.7816315 ,  1.5690155 ],\n",
       "              [ 0.8052521 ,  2.0140076 ],\n",
       "              [ 0.6467743 ,  2.223465  ],\n",
       "              [ 2.097168  ,  2.3927612 ],\n",
       "              [ 0.37799072, -0.02333069],\n",
       "              [ 1.6502686 ,  2.116043  ],\n",
       "              [ 2.3476562 ,  0.20310974],\n",
       "              [ 0.7958374 ,  1.8496399 ],\n",
       "              [ 1.2472839 ,  2.0888672 ],\n",
       "              [ 0.9823761 ,  1.7615662 ]]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_np = np.array([0., 0.2, 1.0, 0])\n",
    "nu_np = np.array([0., 0.2, 1.0, 0])\n",
    "k1_np = np.array([1., 70., 1, 70])\n",
    "k2_np = np.array([1., 60., 1, 70])\n",
    "lam_np = np.array([1., 15., 1, 6])\n",
    "\n",
    "rng_key = random.PRNGKey(190)\n",
    "bvms_b = BivariateVonMises(mu = mu_np, nu = nu_np, k1 = k1_np, k2 = k2_np, lam = lam_np)\n",
    "angles_parallel = bvms_b.sample(rng_key, (10,2))\n",
    "bvms_b.log_prob(angles_parallel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One distributions – initialising by inputting float/int values instead of np.arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.543272018432617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[ 2.1934967 ,  1.5111694 ],\n",
       "             [ 0.78448486,  2.1410522 ],\n",
       "             [ 1.767456  ,  2.045288  ],\n",
       "             [ 0.78352356,  0.79045105],\n",
       "             [ 0.22862244,  1.3271484 ],\n",
       "             [ 1.6169128 ,  1.203064  ],\n",
       "             [ 1.8097839 ,  1.9964752 ],\n",
       "             [ 2.0511017 ,  2.1817474 ],\n",
       "             [ 1.5403137 ,  1.789917  ],\n",
       "             [-2.4478607 ,  1.0534668 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = 0.\n",
    "nu = 0.\n",
    "k1 = 60.\n",
    "k2 = 70.\n",
    "lam = 15.\n",
    "bvms_a = BivariateVonMises(mu = mu, nu = nu, k1 = k1, k2 = k2, lam = lam)\n",
    "rng_key = random.PRNGKey(190)\n",
    "\n",
    "n = 100000\n",
    "start = time.time()\n",
    "angles = bvms_a.sample(rng_key, (10,2))\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)\n",
    "bvms_a.log_prob(angles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialising one distribution – the parameters are given as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.044559001922607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray([[[ 2.11438   ,  0.79042053,  1.8670349 ,  0.4592743 ],\n",
       "              [ 1.5663757 , -3.3298264 ,  1.8549805 ,  1.0588074 ]],\n",
       "\n",
       "             [[ 2.2818146 ,  1.4681396 ,  1.618042  ,  2.0597076 ],\n",
       "              [ 0.9524536 , -0.49378204,  1.9419403 , -7.6818085 ]],\n",
       "\n",
       "             [[ 2.0222168 ,  0.67692566,  1.8776093 ,  1.075531  ],\n",
       "              [ 2.0820465 ,  2.296341  ,  0.99017334,  1.7017059 ]],\n",
       "\n",
       "             ...,\n",
       "\n",
       "             [[ 2.0026398 ,  1.7684784 ,  2.0164642 ,  2.1496887 ],\n",
       "              [-0.7746048 ,  2.0533905 ,  1.1659546 ,  1.0926361 ]],\n",
       "\n",
       "             [[ 2.0525513 ,  1.295105  ,  1.5915985 ,  1.1075897 ],\n",
       "              [ 1.1691742 ,  1.4136047 ,  2.1525269 ,  2.246231  ]],\n",
       "\n",
       "             [[ 2.0267487 ,  0.89372253,  1.9060516 , -0.22383118],\n",
       "              [ 1.497757  ,  1.9042053 , -0.39237213,  0.8095703 ]]],            dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = np.array([0])\n",
    "nu = np.array([0])\n",
    "k1 = np.array([60])\n",
    "k2 = np.array([70])\n",
    "lam = np.array([15])\n",
    "bvms_a = BivariateVonMises(mu = mu, nu = nu, k1 = k1, k2 = k2, lam = lam)\n",
    "rng_key = random.PRNGKey(190)\n",
    "\n",
    "n = (100000, 2, 4)\n",
    "start = time.time()\n",
    "angles = bvms_a.sample(rng_key, n)\n",
    "end = time.time()\n",
    "\n",
    "print(end-start)\n",
    "\n",
    "bvms_a.log_prob(angles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
